{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Lab\n",
    "\n",
    "Shrihan Avilala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Work (10 Points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$I  = \\int_a^b (20 - x^2)\\,dx \\\\[6pt] $\n",
    "  $ = \\int_a^b 20\\,dx - \\int_a^b x^2\\,dx \\\\[6pt]$\n",
    "   $= \\left[ 20x - \\tfrac{x^3}{3} \\right]_a^b  \\\\[6pt]$\n",
    "  $ = \\big(20b - 20a\\big) - \\left(\\tfrac{b^3}{3} - \\tfrac{a^3}{3}\\right) \\\\[6pt]$\n",
    "   $ = 20(b-a) - \\tfrac{1}{3}\\big(b^3 - a^3\\big) $\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x:float) -> float:\n",
    "    return 20-x*x\n",
    "\n",
    "def integral_true(a:float, b:float) -> float:\n",
    "    return 20*(b-a) - (b**3-a**3)/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Monte Carlo (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbb{E^p}[I_n^{\\text{Basic}}] = \\int_{a}^{b} f(x)\\,dx = I $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import numpy\n",
    "def mc_basic(f: Callable[[float], float], a: float, b: float, n: int) -> tuple[float, float]:\n",
    "    estimates = numpy.empty(n)\n",
    "    for index in range(n-1):\n",
    "        f_x_rand = f(numpy.random.uniform(a, b))\n",
    "        probability = 1/(b-a)\n",
    "        estimates[index] = f_x_rand/probability\n",
    "    I_n = numpy.mean(estimates)\n",
    "    basic_var  = numpy.var(estimates)/n\n",
    "    return I_n, basic_var\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\displaystyle Var(I_n^{\\text{Basic}}) = \\frac{1}{n} Var(\\frac{f(x)}{p(x)})\\\\[6pt]$\n",
    "$ \\displaystyle= \\frac{1}{n}\\,Var(\\,(20-x^2)(b-a)\\,) \\\\[6pt]$\n",
    "$ \\displaystyle= \\frac{1}{n}\\,(b-a)\\,Var(\\,20-x^2\\,) \\\\[6pt]$\n",
    "$ \\displaystyle= \\frac{1}{n}\\,(b-a)(\\,\\mathbb{E[\\,(20-x^2)^2\\,]}-\\mathbb{E[\\,(20-x^2)\\,]}^2) \\\\[6pt]$\n",
    "$ \\displaystyle= \\frac{1}{n}\\,(b-a)(\\,\\mathbb{E[\\,400-40x^2+x^4\\,]} - \\mathbb{E[\\,(20-x^2)\\,]}^2\\,) \\\\[6pt]$\n",
    "$ \\displaystyle= \\frac{1}{n}\\,(b-a)(\\frac{1}{b-a}\\int_a^b 400-40x^2+x^4\\,dx - (\\,\\frac{1}{b-a}\\int_a^b 20-x^2\\,dx\\,)^2) \\\\[6pt]$\n",
    "$ \\displaystyle= \\frac{1}{n}\\,(b-a)(400 - \\frac{40}{3}\\,(a^2 + ab + b^2) $\n",
    "$ + \\frac{1}{5}\\,(a^4 + a^3b + a^2b^2 + ab^3 + b^4) - \\left(20 - \\tfrac{1}{3}(a^2 + ab + b^2)\\right)^2)\\\\[6pt] $\n",
    "$ \\displaystyle= \\frac{1}{n}\\,(b-a)\\left(\\frac{4}{45}(a^4+b^4) - \\frac{1}{45}(a^3b+ab^3) - \\frac{2}{15}a^2b^2\\right) $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_basic_variance_true(a: float, b: float, n: int) -> float:\n",
    "    return (1/n)*(b-a)*( (4*(a**4+b**4)/45) - ((b*a**3+a*b**3)/45) - (2*a**2*b**2)/15 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70.66666666666667,\n",
       " 70.69985113575589,\n",
       " 0.033184469089221125,\n",
       " 0.001074439887620132,\n",
       " 107.4439887620132,\n",
       " 0.00027022222222222226,\n",
       " 107.4439887620132)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=100000\n",
    "a=-1\n",
    "b=3\n",
    "\n",
    "integral_true_metric = integral_true(a, b)\n",
    "trial = mc_basic(f, a, b, n)\n",
    "integral_estimate = trial[0]\n",
    "difference = integral_estimate-integral_true_metric\n",
    "var_estimate = trial[1]\n",
    "var_estimate_comparable=var_estimate*n\n",
    "var_true = mc_basic_variance_true(a, b, n)\n",
    "var_true_comparable = var_true*n\n",
    "\n",
    "integral_true_metric, integral_estimate, difference, var_estimate, var_estimate_comparable, var_true, var_estimate_comparable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Antithetic uniform samples (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\displaystyle \\mathbb{E^p}[I_n^{\\text{Antithetic}}] = \\mathbb{E^p} [\\, \\frac{1}{n/2} \\sum_{i=1}^{n/2} \\frac{1}{2} \n",
    "\\left( \\frac{f(x_i)}{p(x_i)} + \\frac{f(\\hat{x}_i)}{p(\\hat{x}_i)} \\right)\\,]$ \n",
    "\n",
    "$ \\displaystyle = \\frac{1}{n} \\, \\mathbb{E^p} [\\, \\sum_{i=1}^{n/2}\n",
    "\\left( \\frac{f(x_i)}{p(x_i)} + \\frac{f(\\hat{x}_i)}{p(\\hat{x}_i)} \\right)\\,] $\n",
    "\n",
    "$ \\displaystyle = \\frac{b-a}{n} \\, \\mathbb{E^p} [\\, \\sum_{i=1}^{n/2}\n",
    "\\left( f(x_i) + f(a+b-x_i) \\right)\\,] \\qquad \\text{(Probability is Uniform and antithetic pairs are symmetric)}$\n",
    "\n",
    "$ \\displaystyle = \\frac{b-a}{n} \\, \\sum_{i=1}^{n/2}\n",
    "\\mathbb{E^p} [\\left( f(x_i) + f(a+b-x_i) \\right)]\\,$\n",
    "\n",
    "$ \\displaystyle = \\frac{b-a}{2} \\,\n",
    "\\mathbb{E^p} [\\left( f(x_i) + f(a+b-x_i) \\right)]\\, $\n",
    "\n",
    "$ \\displaystyle = \\frac{1}{2} \\,\n",
    "\\int_a^b \\left( f(x) + f(a+b-x) \\right)dx\\, $\n",
    "\n",
    "$ \\displaystyle = \\frac{1}{2} \\,\n",
    "\\int_a^b \\left( 20-x^2+20-(a+b-x)^2 \\right)dx\\, $\n",
    "\n",
    "$ \n",
    "= 20(b-a) - \\frac{1}{3}\\big(b^3 - a^3\\big) $\n",
    "\n",
    "$ \\displaystyle =I$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_antithetic(f: Callable[[float], float], a: float, b: float, n: int) -> tuple[float, float]:\n",
    "    estimates = numpy.empty(n//2, dtype=numpy.float64)\n",
    "    ant_estimates = numpy.empty(n//2, dtype=numpy.float64)\n",
    "    for index in range(n//2-1):\n",
    "        x_rand = numpy.random.uniform(a, b)\n",
    "        estimates[index] = f(x_rand)*(b-a)\n",
    "        ant_estimates[index] = f(a+b-x_rand)*(b-a)\n",
    "    I_n = (numpy.mean(estimates)+numpy.mean(ant_estimates))/2\n",
    "    antithetic_var = numpy.var( numpy.concatenate([estimates,ant_estimates]), ddof=1)/n\n",
    "    return I_n, antithetic_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.66666666666667 70.65628217833321 0.0010847212993431927\n"
     ]
    }
   ],
   "source": [
    "n=100000\n",
    "a=-1\n",
    "b=3\n",
    "\n",
    "integral_true_metric = integral_true(a, b)\n",
    "trial = mc_antithetic(f, a, b, n)\n",
    "integral_estimate = trial[0]\n",
    "difference = integral_estimate-integral_true_metric\n",
    "var_estimate = trial[1]\n",
    "var_estimate_comparable=var_estimate*n\n",
    "integral_true_metric, integral_estimate, difference, var_estimate, var_estimate_comparable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance is smaller with antithetic sampling compared to basic sampling. This is expected because random draws that are outliers tend to be cancelled out by picking a number that is symmetrically on the opposite end of the interval. Consequently, the average tends to remains stable, which helps reduce the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Control Variate (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\displaystyle \\text{Let} \\int_a^b {h(x)p(x)}\\,dx = H. $\n",
    "\n",
    "$ \\displaystyle \\mathbb{E^p[I_n^\\text{ControlVariate}]} = \\mathbb{E^p} [\\, \\frac{1}{n} \\sum_{i=1}^{n}\n",
    " \\frac{f(x_i)-h(x_i)}{p(x_i)} + H]\\, $\n",
    "\n",
    "$ \\displaystyle = \\frac{1}{n} \\sum_{i=1}^{n}\\mathbb{E^p[\\frac{f(x_i)}{p(x_i)}]} - \\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{E^p[\\frac{h(x_i)}{p(x_i)}]}+\\mathbb{E^p[H]}$\n",
    "\n",
    "$ \\displaystyle = \\frac{1}{n} \\sum_{i=1}^{n}\\mathbb{E^p[\\frac{f(x_i)}{p(x_i)}]} + \\int_a^b {h(x)p(x)}\\,dx - \\int_a^b {h(x)p(x)}\\,dx$\n",
    "\n",
    "$ = I $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def h1(x: float) -> float:\n",
    "    return 20 * math.cos(x/3)\n",
    "\n",
    "def h2(x: float) -> float:\n",
    "    return 20*math.sin(x/3)\n",
    "\n",
    "def H1(a: float, b: float) -> float:\n",
    "    # Since int(cos(x/3)) = 3sin(x/3)\n",
    "    return -60*math.sin(a/3) + 60*math.sin(b/3)\n",
    "\n",
    "def H2(a: float, b: float) -> float:\n",
    "    return 60*math.cos(a/3) - 60*math.cos(b/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mc_control_variate(f: Callable[[float], float], a: float, b: float, n: int, h: Callable[[float], float], H: Callable[[float, float], float]) -> tuple[float, float]:\n",
    "    estimates = numpy.empty(n)\n",
    "    for each in range(n-1):\n",
    "        x_rand = numpy.random.uniform(a, b)\n",
    "        estimates[each] = (f(x_rand) - h(x_rand))*(b-a)\n",
    "        \n",
    "    I_n = numpy.mean(estimates) + H(a, b)\n",
    "    control_var = numpy.var(estimates) / n\n",
    "    return I_n, control_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12618400862083945"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=100000\n",
    "a=-1\n",
    "b=3\n",
    "\n",
    "integral_true_metric = integral_true(a, b)\n",
    "trial = mc_control_variate(f, a, b, n, h1, H1)\n",
    "integral_estimate = trial[0]\n",
    "difference = integral_estimate-integral_true_metric\n",
    "var_estimate = trial[1]\n",
    "var_estimate_comparable=var_estimate*n\n",
    "\n",
    "integral_true_metric, integral_estimate, difference, var_estimate, var_estimate_comparable\n",
    "\n",
    "trial = mc_control_variate(f, a, b, n, h2, H2)\n",
    "integral_estimate = trial[0]\n",
    "difference = integral_estimate-integral_true_metric\n",
    "var_estimate = trial[1]\n",
    "var_estimate_comparable=var_estimate*n\n",
    "\n",
    "integral_true_metric, integral_estimate, difference, var_estimate, var_estimate_comparable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$20\\cos(x/3)$ has less variance because it has a higher covariance with f(x), which means that the estimations, which are the difference of f(x) and h(x), are brought closer to 0, which inhernetly reduces variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance was less than the basic Monte Carlo estimator, which was what I expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Importance Sampling (25 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $ \\tilde{p}(\\cdot)$ be the uniform distribution and $p(\\cdot)$ be the normal distribution. \n",
    "\n",
    "$ \\displaystyle \\mathbb{E^p[I_n^\\text{Importance}]} = \\mathbb{E^p} [\\, \\frac{1}{n} \\sum_{i=1}^{n}\n",
    " \\frac{f(x_i)\\,\\tilde{p}(x_i)}{p(x_i)}]\\, $\n",
    "\n",
    "$ \\displaystyle  = \\int_a^b { \\frac{f(x)\\,\\tilde{p}(x)}{p(x)}p(x)\\,dx} $\n",
    "\n",
    "$ \\displaystyle  = \\int_a^b {f(x)\\,\\tilde{p}(x)\\,dx} $\n",
    "\n",
    "$ =  \\displaystyle \\mathbb{E^{\\tilde{p}}[I_n^\\text{Importance}]} $\n",
    "\n",
    "$ = I $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def mc_importance(f: Callable[[float], float], a: float, b: float, n: int, sigma: float) -> tuple[float, float, float]:\n",
    "        \n",
    "        estimates = numpy.zeros(n)\n",
    "        for each in range(n-1):\n",
    "                # f(x) = 20-x^2 is centered at x=0\n",
    "                x_rand = numpy.random.normal(0, sigma)\n",
    "                if x_rand < - 1 or x_rand>3:\n",
    "                        continue\n",
    "                estimates[each] = ( f(x_rand) * (1/(b-a))) / (norm.pdf(x_rand, 0, sigma))\n",
    "        \n",
    "        estimates = estimates[estimates != 0]\n",
    "        I_n = numpy.mean(estimates) \n",
    "        control_var = numpy.var(estimates) / len(estimates)\n",
    "        return I_n, control_var, len(estimates)\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.66666666666667 21.167101570652267 -49.49956509601441 0.010613028771691084 1061.3028771691083 83946\n",
      "70.66666666666667 28.300190018285125 -42.36647664838155 0.00029199908457026185 29.199908457026186 62611\n",
      "70.66666666666667 37.438193176253755 -33.22847349041292 9.586548972390413e-06 0.9586548972390413 46986\n",
      "70.66666666666667 47.518946297613375 -23.147720369053296 0.00031322051389043787 31.322051389043786 37341\n",
      "70.66666666666667 57.95855542979929 -12.708111236867381 0.0010767261215863459 107.67261215863459 30453\n",
      "70.66666666666667 68.55127274141353 -2.1153939252531444 0.0024023894018727586 240.23894018727586 25701\n",
      "70.66666666666667 79.16511281828453 8.498446151617856 0.004382970906691908 438.2970906691908 22126\n",
      "70.66666666666667 90.38479338818061 19.71812672151394 0.006688533104636039 668.853310463604 19656\n",
      "70.66666666666667 101.05226857986135 30.385601913194677 0.010215057913159862 1021.5057913159861 17487\n"
     ]
    }
   ],
   "source": [
    "n=100000\n",
    "a=-1\n",
    "b=3\n",
    "\n",
    "integral_true_metric = integral_true(a, b)\n",
    "for each in range(1, 11):\n",
    "    trial = mc_importance(f, a, b, n, each)\n",
    "    integral_estimate = trial[0]\n",
    "    difference = integral_estimate-integral_true_metric\n",
    "    var_estimate = trial[1]\n",
    "    var_estimate_comparable=var_estimate*n\n",
    "    n_used = trial[2]\n",
    "    print(integral_true_metric, integral_estimate, difference, var_estimate, var_estimate_comparable, n_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard deviation $\\sigma=6$ was the best approximation because it had the most covariance with $f(x)$\n",
    "\n",
    "The variance was roughly 5-30x less with importance sampling than basic sampling, which is expected because importance sampling reduces variance by cancelling out much of the highs and lows of the function by dividing them with corresponding probabilities.\n",
    "\n",
    "As $\\sigma$ increased, n_used decreased because as the normal distribution gets wider, values further away from the mean are more likely to be drawn. Since we limit draws to the interval $[-1, 3]$, this means more values are not selected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
